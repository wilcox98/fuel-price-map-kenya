{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2022 Data Cleaning and Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from geopy.geocoders import Nominatim\n",
    "import matplotlib.pyplot as plt\n",
    "import helpers\n",
    "geolocator = Nominatim(user_agent=\"epra\")\n",
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = os.environ.get('BASE_URL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load files\n",
    "Due to different file formats. Each file downloaded is treated as am individual data source.\n",
    "A lot of manual cleaning was done using Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the data files\n",
    "jan = pd.read_csv(f'{BASE_URL}/data/raw/22/15th-January-14th-February-2022.csv')\n",
    "feb = pd.read_csv(f'{BASE_URL}/data/raw/22/15th-February-14th-March-2022_Website.csv')\n",
    "march = pd.read_csv(f'{BASE_URL}/data/raw/22/15th-March-2022-to-April-2022.csv')\n",
    "april = pd.read_csv(f'{BASE_URL}/data/raw/22/15th-April-2022-14th-May-2022.csv')\n",
    "may = pd.read_csv(f'{BASE_URL}/data/raw/22/Pump-Prices11-15-May-14-June-2022_Website.csv')\n",
    "june = pd.read_csv(f'{BASE_URL}/data/raw/22/Pump-Prices-15-June-14-July-2022_Website.csv')\n",
    "july = pd.read_csv(f'{BASE_URL}/data/raw/22/Prices-july-to-August-2022.csv')\n",
    "\n",
    "august = pd.read_csv(f'{BASE_URL}/data/raw/22/Prices-August-to-September-2022.csv')\n",
    "sept = pd.read_csv(f'{BASE_URL}/data/raw/22/Prices-september-to-october-2022.csv')\n",
    "oct1 = pd.read_csv(f'{BASE_URL}/data/raw/22/Prices-Oct-to-Nov-2022.csv')\n",
    "nov = pd.read_csv(f'{BASE_URL}/data/raw/22/Prices-15th-Nov-14th-Dec-2022.csv')\n",
    "dec = pd.read_csv(f'{BASE_URL}/data/raw/22/15th-December-2022-14th-January-2023.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Prepare data for the first half of the year since the data is in the same format\"\"\"\n",
    "def prep_data_jan_jun(data_list):\n",
    "    dfs = []\n",
    "    for data in data_list:\n",
    "        # remove whatespaces in columns\n",
    "        df = helpers.remove_column_whitespace(data)\n",
    "\n",
    "        # clean the date\n",
    "        df['Price_Period'] = helpers.sanitize_date(df, 'Price_Period')\n",
    "        # Fix typos\n",
    "        df = helpers.rename_towns(df)\n",
    "        # Get town coordinates\n",
    "        df = helpers.get_town_coordinates(df, 'Town')\n",
    "        #  drop towns without coords\n",
    "        df = df.dropna()\n",
    "        dfs.append(df)\n",
    "    combined = pd.concat(dfs)\n",
    "    return combined\n",
    "\n",
    "\"\"\"Prepare data for the second half of the year since the data is in the same format\"\"\"\n",
    "def prep_data_jul_dec(data_list):\n",
    "    dfs = []\n",
    "    for data in data_list:\n",
    "        period = data.columns[1]\n",
    "\n",
    "        data.rename(columns={'Unnamed: 0': 'Price_Period', f'{period}': 'Town',\n",
    "                    'MAXIMUM PUMP PRICES': 'Super', 'Unnamed: 3': 'Diesel', 'Unnamed: 4': 'Kerosene'}, inplace=True)\n",
    "        print(period)\n",
    "        df = data.dropna()\n",
    "        # df = data\n",
    "\n",
    "        # set the period\n",
    "        df['Price_Period'] = df['Price_Period'].apply(lambda s: f'{period}')\n",
    "\n",
    "        # clean the date\n",
    "        df['Price_Period'] = helpers.sanitize_date(df, 'Price_Period')\n",
    "        # # Fix town typos\n",
    "        df = helpers.rename_towns(df)\n",
    "        # # Get town coordinates\n",
    "        df = helpers.get_town_coordinates(df, 'Town')\n",
    "        # #  drop towns without coords\n",
    "        df = df.dropna()\n",
    "        dfs.append(df)\n",
    "    combined = pd.concat(dfs)\n",
    "    return combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for the second part of the year\n",
    "first_half_2022 = prep_data_jan_jun([jan, feb, march, april, may, june])\n",
    "first_half_2022\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for the second part of the year\n",
    "second_half_2022 = prep_data_jul_dec([july, august, sept, oct1, nov, dec])\n",
    "second_half_2022.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the dataframes to create the 2022 dataset\n",
    "year_2022 = pd.concat([first_half_2022, second_half_2022])\n",
    "year_2022.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write export it as a csv\n",
    "year_2022.to_csv(f'{BASE_URL}/data/combined.csv',index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
